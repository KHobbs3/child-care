{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Address cleaning\n",
    "\n",
    "**IN:** merged file\n",
    "\n",
    "**OUT:** parsed file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from postal.parser import parse_address\n",
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/kt/Documents/work/STATCAN/ODECF/Wrangling-ODECF/output/childcare/merged/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('childcare-merged.csv')\n",
    "df['source_full_address'] = df['full_address']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1: Full address cleaning\n",
    "\n",
    "**Globally:**\n",
    "1. Remove box numbers, parentheses, phone numbers \n",
    "2. Remove postal codes and fill in `postal_code` column\n",
    "\n",
    "2b. General processing\n",
    "\n",
    "**Targeted:** to remove city (and province) names from full address\n",
    "3. Remove unneccessary commas \n",
    "    * AB, MB, SK, PE, YK, QC\n",
    "4. Add 2-letter province abbreviations and country where neccessary\n",
    "    * NB, PE\n",
    "    \n",
    "5. Add \", Canada\" where neccessary\n",
    "    * GoDayCare, MB, SK\n",
    "    * format: `101 main street AB, Canada`\n",
    "    \n",
    "6. Remove concatenated \"city 2-letter prov, Canada\"\n",
    "    * ensure formats are met apriori\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phone_rmv(x):\n",
    "    \"\"\"To remove phone numbers structured as ' (XXX) XXX-XXXX' from full address column.\"\"\"\n",
    "    try:\n",
    "        p = re.compile('\\s\\(\\d{3}\\)\\s\\d{3}\\-\\d{4}')\n",
    "        p.search(x)[0]\n",
    "        update = x.replace(p.search(x)[0], '')\n",
    "        return update\n",
    "    except TypeError:\n",
    "        return x\n",
    "    \n",
    "df.full_address = df.full_address.map(phone_rmv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcs=[]\n",
    "def pc_extract(x):\n",
    "    \"\"\"To extract postal code from full address and place in list, \n",
    "    which can be appended to df and fill NAs in postal code column.\n",
    "    Also returns full address with postal code removed.\"\"\"\n",
    "    try:\n",
    "        pc = re.compile('[a-zA-Z]{1}\\d{1}[A-Za-z]{1}\\s\\d{1}[A-Za-z]{1}\\d{1}')\n",
    "        pcs.append(pc.search(x)[0])\n",
    "        return x.replace(pc.search(x)[0], '')\n",
    "    except TypeError:\n",
    "        pcs.append(None)\n",
    "        return x\n",
    "    \n",
    "df.full_address = df.full_address.map(pc_extract)\n",
    "\n",
    "# fill missing postal codes from what was extracted from full address using pc_extract\n",
    "df.postal_code.fillna(value = pd.Series(pcs),inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2b. General processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.full_address = df.full_address.astype(str)\n",
    "\n",
    "# replace bad regex\n",
    "df.full_address.replace({\n",
    "    r'\\bappartement\\b ' : r'unit #',\n",
    "    r'\\bapt\\b ' : r'unit #',\n",
    "    r'\\bsuite\\b ' : r'#',\n",
    "    r'\\bSUITE\\b ' : r'#', \n",
    "    r'\\brd\\b #\\d+' : r'road \\d+',\n",
    "    r'\\broad\\b #\\d+' : r'road \\d+',\n",
    "    r'\\bhwy\\b #\\d+': r'highway \\d+',\n",
    "    r'\\bhighway\\b #\\d+': r'highway \\d+'\n",
    "    }, inplace = True)\n",
    "\n",
    "# remove bad regex\n",
    "bad = [\n",
    "    'ecole new era school m6',\n",
    "    r':',\n",
    "    r'\\&',\n",
    "    r'\\bbureau\\b \\d+',\n",
    "    r'\\bbureau\\b [a-zA-Z]',\n",
    "    r'\\bBox\\b \\d+',\n",
    "    r'\\blocal\\b [a-zA-Z]',\n",
    "    r'\\blocal\\b [a-zA-Z]\\d+',\n",
    "    r'\\blocal\\b \\d+',\n",
    "    r'\\bsuite\\b \\d+[a-zA-Z]',\n",
    "    r'\\bCP\\b \\d+',\n",
    "    r'\\bgym\\b',\n",
    "    r'\\bgymnasium\\b',\n",
    "    r'\\blibrary\\b \\d+',\n",
    "    r'\\,',\n",
    "    r'\\(.*\\)'\n",
    "]\n",
    "\n",
    "for b in bad:\n",
    "    df.full_address = df.full_address.map(lambda x: re.sub(b,'',x))\n",
    "\n",
    "    \n",
    "#------------------------------\n",
    "\n",
    "\n",
    "# remove commas from QC\n",
    "df.loc[df.provider == 'Province of Quèbec', 'full_address'] = df.loc[df.provider == 'Province of Quèbec', 'full_address'].replace({',':''}, regex = True)\n",
    "\n",
    "# replace dashes except from QC\n",
    "df.loc[df.provider != 'Province of Quèbec', 'full_address']=df.loc[df.provider != 'Province of Quèbec', 'full_address'].replace('-',' ',regex=True)\n",
    "\n",
    "# replace periods\n",
    "df.full_address=[x.replace('.','') for x in df.full_address.astype('str')]\n",
    "\n",
    "#replace multiple spaces\n",
    "df.full_address=df.full_address.replace(' +',' ',regex=True)\n",
    "\n",
    "# remove trailing white space\n",
    "df.full_address=df.full_address.str.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find obvious errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rue Gigaire 2e étage index: 5467\n",
      "rue Drummond 4e étage index: 5844\n",
      "rue Berri 1er étage index: 5899\n",
      "rue Delisle 2e étage index: 5912\n",
      "rue Masson 2e étage index: 6349\n",
      "rue Bonsecours 3e étage index: 6390\n",
      "rue Bonsecours 2e étage index: 6402\n",
      "rue Bonsecours 1er étage index: 6462\n",
      "rue Bannantyne 2e étage index: 6770\n",
      "rue Rodrigue 2e étage index: 7608\n"
     ]
    }
   ],
   "source": [
    "# errors: road mill, road quispamsis, road sainte anne, road beaverbrook, road road,\n",
    "# ok: road ragged, road\\s, road old shediac, road macdonald, 3359 Cloverside Road Avon Cloverside road Avonmore ON (godaycare), road allowance\n",
    "ind = -1\n",
    "def find_weird_roads(x):\n",
    "    try:\n",
    "#         rg1 = r'road [a-zA-Z]*' # english\n",
    "        rg2 = r'rue [a-zA-Z]* [0-9].*' # french\n",
    "        rg3 = r'rue [0-9].*' # french\n",
    "#         return re.search(rg1, x)[0]\n",
    "        return re.search(rg2, x)[0]\n",
    "    except TypeError:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "def find_weird_hwys(x):\n",
    "    try:\n",
    "        rg1 = r'highway [a-zA-Z]*'\n",
    "        rg2 = r'highway [0-9]*'\n",
    "        return re.search(rg1, x)[0]\n",
    "        return re.search(rg2, x)[0]\n",
    "    except TypeError:\n",
    "        pass\n",
    "\n",
    "# for f in df.full_address:\n",
    "#     ind += 1\n",
    "#     if find_weird_roads(f) != None:\n",
    "#         print(find_weird_roads(f), \"index: {}\".format(ind))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix obvious errors\n",
    "* rearrange units at end of address to start\n",
    "* rearrange roads for found errors\n",
    "* add hastag to french floors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rearrange_units(x):\n",
    "#     '''function to place unit number (denoted by #) at the start of string'''\n",
    "#     try:\n",
    "#         unit = re.search(r'#\\d+', x)[0]\n",
    "#         rest = x.replace(unit, '')\n",
    "#         return '{} {}'.format(unit, rest)\n",
    "#     except TypeError:\n",
    "#         pass\n",
    "#     return x\n",
    "\n",
    "# t = '3100 B STEWART CREEK DRIVE #001'\n",
    "# out = rearrange(t)\n",
    "# parse_address(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['rearranged_units'] = df.full_address.map(rearrange_units)\n",
    "# df['rearranged_parsed'] = df.rearranged.map(parse_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rearrange_roads(x):\n",
    "    '''function to place errors: \n",
    "    road mill, road quispamsis, road sainte anne, road beaverbrook, road road'''\n",
    "    try:\n",
    "        if 'road mill' in x:\n",
    "            return x.replace('road mill', 'mill road')\n",
    "        elif 'road quispamsis' in x:\n",
    "            return x.replace('road quispamsis', 'quispamsis road')\n",
    "        elif 'road sainte anne' in x:\n",
    "            return x.replace('road sainte anne', 'sainte anne road')\n",
    "        elif 'road beaverbrook' in x:\n",
    "            return x.replace('road beaverbrook', 'beaverbrook road')\n",
    "        elif 'road road' in x:\n",
    "                return x.replace('road road', 'road')\n",
    "    except TypeError:\n",
    "        pass\n",
    "    return x\n",
    "\n",
    "df.loc[df.provider == 'Province of New Brunswick', 'full_address'] = df.loc[df.provider == 'Province of New Brunswick', 'full_address'].map(rearrange_roads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_fr_floor(x):\n",
    "    ''' adds hashtag to french floors for easy parsing'''\n",
    "    try:\n",
    "        m = re.search(r'[0-9]e étage', x)[0]\n",
    "        return x.replace(m, '#'+m)\n",
    "    except TypeError:\n",
    "        pass\n",
    "    return x\n",
    "    \n",
    "df.loc[df.provider == 'Province of Quèbec', 'full_address'] = df.loc[df.provider == 'Province of Quèbec', 'full_address'].map(fix_fr_floor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('775', 'house_number'), ('rue bonsecours', 'road'), ('#2e étage', 'level')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_address(df.iloc[6402].full_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[['source_full_address','full_address','street_number','street_name', 'unit', 'rearranged_units', 'rearranged_parsed']].to_csv('../check_units.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Remove unneccessary commas \n",
    "    * AB, MB, SK, PE, YT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "slct = ['Alberta', 'Manitoba', 'Saskatchewan', 'Prince Edward Island']\n",
    "\n",
    "for s in slct:\n",
    "    df.loc[df.provider == 'Province of {}'.format(s), 'full_address'] = df.loc[df.provider == 'Province of {}'.format(s), 'full_address'].replace({',': ''}, regex = True)\n",
    "    \n",
    "df.loc[df.provider == 'Yukon Territory', 'full_address']=df.loc[df.provider == 'Yukon Territory', 'full_address'].replace({',': ''}, regex = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Add 2-letter province abbreviations and country where neccessary\n",
    "    * NB, PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add prov to new brunswick and pei to catch cities for removal\n",
    "df.full_address = df.full_address.astype(str)\n",
    "df.loc[df.provider == 'Province of New Brunswick', 'full_address'] = df.loc[df.provider == 'Province of New Brunswick', 'full_address'].map(lambda x: x + \" NB, Canada\")\n",
    "df.loc[df.provider == 'Province of Prince Edward Island', 'full_address'] = df.loc[df.provider == 'Province of Prince Edward Island', 'full_address'].map(lambda x: x + \" PE, Canada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Add \", Canada\" where neccessary\n",
    "    * GoDayCare, MB, SK\n",
    "    * format: `101 main street AB, Canada`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.provider == 'GoDayCare.com', 'full_address'] = df.loc[df.provider == 'GoDayCare.com', 'full_address'].map(lambda x: x + \", Canada\")\n",
    "df.loc[df.provider == 'Province of Manitoba', 'full_address'] = df.loc[df.provider == 'Province of Manitoba', 'full_address'].map(lambda x: x + \", Canada\" if x != \"None\" else x)\n",
    "df.loc[df.provider == 'Province of Saskatchewan', 'full_address'] = df.loc[df.provider == 'Province of Saskatchewan', 'full_address'].map(lambda x: x.strip() + \", Canada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Remove concatenated \"city 2-letter prov, Canada\"\n",
    "    * ensure formats are met apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab list of all cities and provinces used in GoDayCare.com facilities\n",
    "godc_prov = df.loc[df.provider == 'GoDayCare.com'].province.astype(str).to_list()\n",
    "godc_cit = df.loc[df.provider == 'GoDayCare.com'].city.astype(str).to_list()\n",
    "\n",
    "\n",
    "# create unique set of city - province concatenations to reference in full_address for removal\n",
    "citprovCA = set()\n",
    "for c,p in zip(godc_cit, godc_prov):\n",
    "    citprovCA.add(\"{} {}, {}\".format(c,p, \"Canada\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prov_abbrev = {\n",
    "              \"Alberta\": \"AB\",\n",
    "              \"British Columbia\": \"BC\",\n",
    "              \"Saskatchewan\": \"SK\",\n",
    "              \"Manitoba\": \"MB\",\n",
    "              \"Ontario\": \"ON\",\n",
    "              \"Quebec\": \"QC\",\n",
    "              \"Newfoundland And Labrador\": \"NL\",\n",
    "              \"New Brunswick\": \"NB\",\n",
    "              \"Nova Scotia\": \"NS\",\n",
    "              \"Northwest Territories\": \"NT\",\n",
    "              \"Nunavut\": \"NU\",\n",
    "              \"Prince Edward Island\": \"PE\",\n",
    "              \"Yukon Territory\": \"YT\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_address(x):\n",
    "    \"\"\"Converts full province name to abbreviated in the reference set.\n",
    "    Returns full address with changes intended for improved parsing efficacy.\"\"\"\n",
    "    for k in prov_abbrev.keys():\n",
    "        try:\n",
    "            mach = re.search(k, x)[0]\n",
    "            return x.replace(mach, prov_abbrev[mach])\n",
    "        except TypeError:\n",
    "            pass\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use cityprov reference database to remove names found in df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.chdir('../parsed/references')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference = set(pd.read_csv('reference.csv').cityprov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cityprov = []\n",
    "def citprov_rmv(x):\n",
    "    '''Removes city, 2-letter prov from \"full_address\" column in pandas DataFrame and \n",
    "    appends it to a global list called \"cityprov\".\n",
    "    cityprov can be used to fill in the \"city\" column where city information was in \"full_address\".'''\n",
    "    for cp in reference:\n",
    "        if cp.lower() in x.lower():\n",
    "#             print(cp)\n",
    "            cityprov.append(cp)\n",
    "            return x.lower().replace(cp.lower(), '')\n",
    "        else:\n",
    "            pass\n",
    "    cityprov.append(None)\n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark> slow!! </mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['full_address'] = df.full_address.map(citprov_rmv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Part 2: Full address parsing\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.full_address = df.full_address.astype(str)\n",
    "parsed = df.full_address.map(parse_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': [],\n",
       " 'city_district': [],\n",
       " 'country_region': [],\n",
       " 'postcode': [],\n",
       " 'po_box': [],\n",
       " 'city': [],\n",
       " 'level': [],\n",
       " 'country': [],\n",
       " 'house_number': [],\n",
       " 'road': [],\n",
       " 'unit': [],\n",
       " 'suburb': [],\n",
       " 'state_district': [],\n",
       " 'house': []}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize dictionary\n",
    "keys = set()\n",
    "for p in parsed:\n",
    "        for v,k in p:\n",
    "            keys.add(k)\n",
    "            \n",
    "parsed_dict = {k: [] for k in keys} \n",
    "parsed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "keylst = [k for k in keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = {k: [] for k in keys} \n",
    "master\n",
    "\n",
    "for p in parsed:\n",
    "    # make a dict of all the keys and values in each address parse\n",
    "    currentkeys = []\n",
    "    \n",
    "    # separate the parsed tuple and add to list\n",
    "    for v,k in p:\n",
    "        currentkeys.append(k)\n",
    "    \n",
    "    # initialize dictionary for current address parse bits\n",
    "    current = {k: [] for k in currentkeys} \n",
    "    \n",
    "    # complete current dictionary\n",
    "    for v,k in p:\n",
    "        current[k] = v\n",
    "        \n",
    "    # iter through all the possible keys in master dict, which need to be of equal length\n",
    "    for masterkey in keylst:\n",
    "        # if theres the dict key in current address, retrieve the value and append it to our master dict\n",
    "        if masterkey in current.keys():\n",
    "            master[masterkey].append(current[masterkey])\n",
    "\n",
    "        # else, append a space holder\n",
    "        else:\n",
    "            master[masterkey].append('')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state 25162\n",
      "city_district 25162\n",
      "country_region 25162\n",
      "postcode 25162\n",
      "po_box 25162\n",
      "city 25162\n",
      "level 25162\n",
      "country 25162\n",
      "house_number 25162\n",
      "road 25162\n",
      "unit 25162\n",
      "suburb 25162\n",
      "state_district 25162\n",
      "house 25162\n"
     ]
    }
   ],
   "source": [
    "for k,v in master.items():\n",
    "    print(k, len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = pd.DataFrame(master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['unit'] = master_df.unit\n",
    "df.street_name.fillna(value = master_df.road, inplace = True)\n",
    "df.street_number.fillna(value = master_df.house_number, inplace = True)\n",
    "df.street_number.fillna(value = master_df.postcode, inplace = True)\n",
    "df.unit.fillna(value = master_df.level, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export 5% sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[['name', 'source_full_address', 'full_address', 'street_number', 'street_name', 'unit', 'city', 'province', 'provider']].sample(int(len(df)*0.05)).to_csv(\"../childcare-0.05-percent.csv\", encoding = \"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Part 3: Completing missing information\n",
    "* province"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.provider == \"Province of Manitoba\", 'province'] = 'MB'\n",
    "df.loc[df.provider == \"Province of Alberta\", 'province'] = 'AB'\n",
    "df.loc[df.provider == \"Province of Saskatchewan\", 'province'] = 'SK'\n",
    "df.loc[df.provider == \"Province of British Columbia\", 'province'] = 'BC'\n",
    "df.loc[df.provider == \"Province of Quèbec\", 'province'] = 'QC'\n",
    "df.loc[df.provider == \"Province of New Brunswick\", 'province'] = 'NB'\n",
    "df.loc[df.provider == \"Province of Newfoundland and Labrador\", 'province'] = 'NL'\n",
    "df.loc[df.provider == \"Province of Nova Scotia\", 'province'] = 'NS'\n",
    "df.loc[df.provider == \"Province of Prince Edward Island\", 'province'] = 'PE'\n",
    "df.loc[df.provider == \"Nunavut\", 'province'] = 'NU'\n",
    "df.loc[df.provider == \"Yukon Territory\", 'province'] = 'YT'\n",
    "df.loc[df.provider == \"Northwest Territories\", 'province'] = 'NT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.province = df.province.map(lambda x: re.sub(x, complete_address(x), x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* fill city column with those removed from the full_address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark> slow!! </mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.city.fillna(value = pd.Series(cityprov), inplace = True)\n",
    "df.city.replace({' NB, Canada' : '',\n",
    "                ' MB, Canada' : '',\n",
    "                ' SK, Canada': ''}, regex= True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[['source_full_address', 'full_address', 'provider', 'city']].to_csv('citprov_removal.csv', encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Tidy columns & Export**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['Unnamed: 0'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "colsort = ['source_id','name','source_facility_type','facility_type',\n",
    "            'ages', 'capacity', 'infant', 'toddler', 'school_age',\n",
    "           'source_full_address', 'full_address','street_number', 'street_name','unit', 'postal_code', 'city', 'province', \n",
    "           'provider','licence_status', 'longitude', 'latitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reindex(colsort, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../childcare-facilities.csv', encoding = 'utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
